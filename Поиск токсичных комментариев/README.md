# Поиск токсичных комментариев



**Цель проекта:**  Обучить модель классификации, которая выявит среди текстов токсичные и отправит их на модерацию.

**Результаты работы:**
   - Мы выполнили очистку данных и разделили их на обучающую и тестовую выборки.
   - Выполнили лемматизацию `WordNet`из пакета `NLTK`
   - Вычислили TF-IDF для корпуса текстов.
   - Мы обучили модель LightGBM, но качество ответов оказалось недостаточным.
   - Лучшие результаты показала логистическая регрессия с результотом f1_score = `0.75`.
   
---

**Библиотеки**: pandas, NumPy, NLTK, scikit-learn, LightGBM.
